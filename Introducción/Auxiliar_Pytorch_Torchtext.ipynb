{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Pytorch & Torchtext"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":193868,"status":"ok","timestamp":1655419862151,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"gsaS37KAzZoj","vscode":{"languageId":"python"}},"outputs":[],"source":["%%capture\n","# Nos aseguramos que torchtext este en la ultima version\n","!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1655419864539,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"bhqLuYsIYTtt","outputId":"028145a9-0e94-4044-df92-336dec9d440e","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Desde una lista de listas\n"," tensor([[2, 3, 4],\n","        [4, 5, 6]])\n","\n","Dimensiones del tensor\n"," torch.Size([2, 3])\n","\n","Numero de dimensiones del tensor\n"," 2\n"]}],"source":["# Creacion a partir de otra estructura\n","a = [[2,3,4], [4,5,6]]\n","t = torch.tensor(a)\n","print(\"Desde una lista de listas\\n\", t)\n","print(\"\\nDimensiones del tensor\\n\", t.size())\n","print(\"\\nNumero de dimensiones del tensor\\n\", t.dim())"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1655419869626,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"tbmxaTNpeeCI","outputId":"8cf6f211-0f5a-4e47-88d0-4b732325a776","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor vacio\n"," tensor([[[2.1200e-33, 0.0000e+00, 3.3631e-44],\n","         [0.0000e+00,        nan, 6.4460e-44]],\n","\n","        [[1.1578e+27, 1.1362e+30, 7.1547e+22],\n","         [4.5828e+30, 1.2121e+04, 7.1846e+22]]])\n"]}],"source":["# Creacion de un tensor \"vacio\"\n","t = torch.empty(2,2,3)\n","print(\"Tensor vacio\\n\", t)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1655419872301,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"n4oh5DZJehaF","outputId":"6ecbb606-59e8-42d5-cd1f-75239ccb64f1","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Puros unos\n"," tensor([[[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]],\n","\n","        [[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]])\n"]}],"source":["# Creacion de tensores con puros 1 o puros ceros\n","t = torch.ones(2,3,4)\n","# t = torch.zeros(2,3,4,5)\n","print(\"Puros unos\\n\", t) # notar la tercera dimension"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1655419874557,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"2PLHgzdMe2cb","outputId":"8070f5de-1f9d-47a3-a38f-77723bf93f49","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Distribucion uniforme\n"," tensor([[0.3605, 0.9104],\n","        [0.4279, 0.8410],\n","        [0.6106, 0.8126]])\n","\n","Distribucion normal\n"," tensor([[-1.4472, -0.7244,  1.8079],\n","        [ 0.8905,  0.2942, -0.9349]])\n"]}],"source":["# Random sampling\n","t = torch.empty(3, 2).uniform_() # notar operacion in-place\n","print(\"Distribucion uniforme\\n\", t)\n","\n","t = torch.randn(2, 3)\n","print(\"\\nDistribucion normal\\n\", t)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1655419876644,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"33AQwoOXobdD","outputId":"3f083725-6385-4d3b-ff68-f88db80bbe4b","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Operaciones con escalares\n"," tensor([[6., 6., 6., 6.],\n","        [6., 6., 6., 6.],\n","        [6., 6., 6., 6.]])\n"]}],"source":["# Operaciones matematicas\n","t = torch.ones(3,4)\n","print(\"Operaciones con escalares\\n\", t + 5)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1655419878507,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"NBINbVumph2W","outputId":"927c2786-84c8-4cc8-d453-6103a7407d81","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Operaciones entre tensores\n","t1 = torch.ones(2, 3)\n","t1"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1655419879613,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"t2fJNHSJisbC","outputId":"92336a06-4d5c-469b-ccc0-0614ab545f35","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Operaciones entre tensores\n"," tensor([[3., 3., 3.],\n","        [3., 3., 3.]])\n"]}],"source":["t2 = torch.ones(2, 3) * 2\n","print(\"Operaciones entre tensores\\n\", t1 + t2)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1655419881013,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"G2ouTAQYXxyH","outputId":"1e37b30b-b2a7-498d-91b5-adb7cb8d69eb","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Suma in-place\n"," tensor([[2., 2., 2.],\n","        [2., 2., 2.]])\n"]}],"source":["# Tambien se pueden hacer operaciones in-place, se modifica el mismo tensor\n","t = torch.ones(2,3)\n","t.add_(1)\n","print(\"Suma in-place\\n\", t)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1655419883318,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"N33ZYc3LYH94","outputId":"3fb7caf7-eab2-4cf3-a27b-95a267ab9d12","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Dimensiones de partida\n"," torch.Size([16])\n","\n","Usamos el metodo .view() y el -1 para que torch infiera dimensiones\n"," torch.Size([2, 8])\n","\n","Podemos volver a aplanar el tensor con .flatten()\n"," torch.Size([16])\n","\n","Podemos agregar dimensiones sin agregar datos con .unsqueeze()\n"," torch.Size([4, 1, 4])\n","\n","Con .squeeze() podemos sacar todas las dimensiones de tamanno 1\n"," torch.Size([4, 4])\n"]}],"source":["# Hay veces que es util reorganizar los datos de un tensor, o agregar\n","# dimensiones \n","t = torch.arange(16)\n","print(\"Dimensiones de partida\\n\", t.shape)\n","\n","t = t.view(-1, 8)\n","print(\"\\nUsamos el metodo .view() y el -1 para que torch infiera dimensiones\\n\", t.shape)\n","\n","t = t.flatten() # Aqui tambien se podria usar .view(-1)\n","print(\"\\nPodemos volver a aplanar el tensor con .flatten()\\n\", t.shape)\n","\n","t = t.view(-1, 4).unsqueeze(1) # tambien podria ser .view(-1, 1, 4)\n","print(\"\\nPodemos agregar dimensiones sin agregar datos con .unsqueeze()\\n\", t.shape)\n","\n","t = t.squeeze()\n","print(\"\\nCon .squeeze() podemos sacar todas las dimensiones de tamanno 1\\n\", t.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1655419892646,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"B6MMvvLpL3ro","outputId":"7ffb51ec-cb78-43b7-858b-73d4ea6deb27","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["dim=0: tensor([ 1.0297, -0.1845,  2.2744, -7.2324, -4.5985,  0.2478,  1.2916,  0.8038,\n","        -0.3246, -1.4856])\n","dim=1: tensor([-2.5060, -0.8198, -0.5575, -4.0351, -0.2600])\n"]}],"source":["# Podemos hacer las tipicas sumas\n","t = torch.randn(5, 10)\n","# dim = 0 es suma de filas y 1 de columnas\n","print(f\"dim=0: {t.sum(dim=0)}\")\n","print(f\"dim=1: {t.sum(dim=1)}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1655419895908,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"Aoqanb1yNtTe","vscode":{"languageId":"python"}},"outputs":[],"source":["# Tal como con numpy podemos hacer funciones\n","def softmax(T, dim):\n","  T = torch.as_tensor(T)\n","  T = T - torch.max(T)\n","  deno = torch.exp(T)\n","  suma = torch.sum(torch.exp(T), dim=dim, keepdim=True)\n","  output = deno/suma\n","  return output"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1655419896922,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"sGcH3FZqOBOz","outputId":"67856941-af2c-4681-976a-dde31bd3892e","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["tensor([[0.0174, 0.0239, 0.0415, 0.0387, 0.0235, 0.0187, 0.1856, 0.0542, 0.0159,\n","         0.0238, 0.0519, 0.0240, 0.0208, 0.0166, 0.0290, 0.0290, 0.0215, 0.0212,\n","         0.0071, 0.0146, 0.0500, 0.0149, 0.0260, 0.0287, 0.0273, 0.0103, 0.0114,\n","         0.0219, 0.0072, 0.0655, 0.0409, 0.0172],\n","        [0.0197, 0.0148, 0.0122, 0.0118, 0.0167, 0.0705, 0.0140, 0.0083, 0.0183,\n","         0.0880, 0.0374, 0.0214, 0.0449, 0.0054, 0.0092, 0.0225, 0.0055, 0.0180,\n","         0.0101, 0.0052, 0.1512, 0.0396, 0.0170, 0.0099, 0.0978, 0.0226, 0.0350,\n","         0.0129, 0.0333, 0.0099, 0.0153, 0.1014],\n","        [0.0074, 0.1372, 0.0033, 0.0159, 0.0269, 0.0399, 0.0010, 0.0167, 0.0883,\n","         0.0024, 0.0065, 0.1752, 0.0234, 0.0129, 0.0301, 0.0176, 0.0071, 0.0117,\n","         0.0187, 0.0037, 0.0683, 0.0129, 0.0387, 0.0243, 0.0056, 0.0105, 0.0152,\n","         0.0197, 0.1199, 0.0140, 0.0120, 0.0131],\n","        [0.0360, 0.0747, 0.0178, 0.0071, 0.0204, 0.0652, 0.0139, 0.0204, 0.0102,\n","         0.0018, 0.0072, 0.0469, 0.0139, 0.0832, 0.0232, 0.0544, 0.0078, 0.0115,\n","         0.0294, 0.0317, 0.0044, 0.0192, 0.1417, 0.0232, 0.0154, 0.0315, 0.0460,\n","         0.0040, 0.0113, 0.0709, 0.0441, 0.0116],\n","        [0.0015, 0.0073, 0.0111, 0.0146, 0.0345, 0.0125, 0.0733, 0.0348, 0.0393,\n","         0.0162, 0.0049, 0.0062, 0.0110, 0.0261, 0.0674, 0.1393, 0.0945, 0.0040,\n","         0.0105, 0.0024, 0.0406, 0.0192, 0.0033, 0.0777, 0.0143, 0.0030, 0.0435,\n","         0.0172, 0.0320, 0.0110, 0.0227, 0.1041]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["t = torch.randn(5, 32)\n","softmax(t, dim=1)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":627,"status":"ok","timestamp":1655419902002,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"e8EjrIZnypw5","outputId":"38bc2126-3646-4eb8-8481-0338c56b201b","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun 16 22:51:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Primero usemos un comando de shell para obtener informacion de la GPU\n","# Recuerden cambiar el runtime del colab\n","!nvidia-smi"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1655419904851,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"VgAok3BJzSWi","outputId":"fa50ac95-24ec-470e-d884-9f460c106e98","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Habemus GPU? True\n","Cuantas GPUs me regala Google? 1\n"]}],"source":["# Verificar si cuda esta disponible en el entorno\n","print(\"Habemus GPU?\", torch.cuda.is_available())\n","if torch.cuda.is_available(): # Usar esto para codigo agnostico\n","    print(\"Cuantas GPUs me regala Google?\", torch.cuda.device_count())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3889,"status":"ok","timestamp":1655419911694,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"D1cyvw3mzeMP","outputId":"f709657c-c3e2-4d5e-9408-1c26b65df0e9","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Los tensores se instancian en la cpu por default\n","Pero se pueden mover al dispositivo cuda:0 usando el methodo .cuda()\n","Tambien se pueden llevar a cuda:0 usando el metodo .to()\n"]}],"source":["# Mover tensores entre gpu y cpu\n","t = torch.empty(3, 4)\n","print(f\"Los tensores se instancian en la {t.device} por default\")\n","\n","t = t.cuda() # .cuda() retorna un nuevo tensor en GPU\n","print(f\"Pero se pueden mover al dispositivo {t.device} usando el methodo .cuda()\")\n","\n","t = torch.empty(3, 4).to(\"cuda\") # Tambien se puede usar con \"cpu\"\n","print(f\"Tambien se pueden llevar a {t.device} usando el metodo .to()\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1655419914065,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"yeYMoyGFv9zO","outputId":"bc56458a-687e-441f-8c3a-ff2ea3d74b6d","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun 16 22:51:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    26W /  70W |   1162MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Veamos el uso de la gpu\n","!nvidia-smi"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1655419916352,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"1IisFuXt1Bqi","outputId":"9ae39a96-633a-408b-e59c-0a3f10285347","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun 16 22:51:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    26W /  70W |   6886MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Ahora creemos un tensor tremendo\n","t = torch.empty(6000, 1000, 1000, device=\"cuda\", dtype=torch.int8) # Cada elemento pesa 1 byte\n","\n","# Y veamos cuanta VRAM estamos usando\n","!nvidia-smi"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":923,"status":"ok","timestamp":1655419939416,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"6z3WpurA4hIx","vscode":{"languageId":"python"}},"outputs":[],"source":["import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"46jrmdTCxmC1"},"source":["# Parte 2: Clasificación de Texto usando la librería torchtext (Embeddings + FeedForward)\n","\n","Ahora usaremos capas de Embedding y en redes feed forward para la clasificación de texto."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5188,"status":"ok","timestamp":1655419950081,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"930w9SpaQoAL","vscode":{"languageId":"python"}},"outputs":[],"source":["%%capture --no-stderr\n","# Comencemos instalando el paquete\n","!pip install torchtext==0.9.0"]},{"cell_type":"markdown","metadata":{"id":"VCYwbzIolQZg"},"source":["## Datos"]},{"cell_type":"markdown","metadata":{"id":"N_a7nTyllOUS"},"source":["Descarguémos el dataset que usaremos en los ejmplos de esta parte de la auxiliar"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1186,"status":"ok","timestamp":1655419998992,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"eiTRFyZBlV_4","outputId":"04db9f80-bc57-40a9-c946-a6e550ff3ca3","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-06-16 22:53:17--  http://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz [following]\n","--2022-06-16 22:53:17--  https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9304385 (8.9M) [application/octet-stream]\n","Saving to: ‘complete_data.csv.gz’\n","\n","complete_data.csv.g 100%[===================>]   8.87M  20.6MB/s    in 0.4s    \n","\n","2022-06-16 22:53:18 (20.6 MB/s) - ‘complete_data.csv.gz’ saved [9304385/9304385]\n","\n"]}],"source":["!wget raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n","# !gunzip complete_data.csv.gz"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1639,"status":"ok","timestamp":1655420006434,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"EvUG4iRIlYHP","outputId":"8ebab5bf-8197-4ab7-b962-1582ad92c365","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Ejemplo aleatorio:\n"," ('Justicia', 'porque a todas las personas se les debe respetar y todo niño tiene derecho a ser escuchado y la justicia es igual para todos.')\n","\n","Ejemplo aleatorio:\n"," ('Bien Común / Comunidad', 'un principio que debe primar es que todas las personas se beneficien a partir de un sistema sustentado, en la ayuda mutua y el compromiso social.')\n","\n","Ejemplo aleatorio:\n"," ('Democracia', 'la democracia es la base para tener un país justo.')\n"]}],"source":["import gzip\n","import csv\n","with gzip.open('complete_data.csv.gz', 'rt') as f:\n","  data = csv.DictReader(f, strict=True, escapechar=\"\\\\\")\n","\n","  # Para este ejemplo solo voy a trabajar con documentos de la categoria 1, \"Valores\"\n","  dataset = tuple(\n","      # Usemos lowercase para que el vocabulario no quede tan grande\n","      (row[\"constitutional_concept\"], row[\"argument\"].lower()) \n","      for row in data if row[\"topic\"] == \"1\" and row[\"argument\"]\n","  )\n","\n","dataset = dataset[:10000]\n","\n","# Mostremos algunos ejemplos\n","from random import sample\n","for example in sample(dataset, 3):\n","    print(\"\\nEjemplo aleatorio:\\n\", example)"]},{"cell_type":"markdown","metadata":{"id":"WvvzxraUlaCY"},"source":["## Splits"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1655420017773,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"iOIc2PHhldJ_","outputId":"ece87a43-d0db-42df-d044-85ddd98724ba","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Algunos ejemplos del dataset:\n","('Respeto / Conservación de la naturaleza o medio ambiente', 'transversal, (salud, economía, educación). sustentabilidad (social). compartir el valor. calidad de vida')\n","('Inclusión', 'no solo inclusio, siono también integrae, incluir a las personas con acapacidades diferentes con igualdad y dignidad. asumirlos como iguales a todos.')\n","('Plurinacionalismo', 'el reconocimiento de los pueblos originarios como nación, en el marco del estado chileno y la toma en cuenta de la diversidad y multiculturalidad del país asegurando el acceso a las condiciones  para vivir y desarrollar su propia identidad . (el desacuerdo se dio sobre la plurinacionalidad)')\n"]}],"source":["# Ahora con este vocabulario podemos armar un set de train y uno de validacion\n","import torch\n","from torch.utils.data.dataset import random_split\n","train_len = int(len(dataset) * .8)\n","\n","train_split, validation_split = random_split(dataset, [train_len, len(dataset) - train_len])\n","\n","print(\"Algunos ejemplos del dataset:\")\n","for example in sample(list(train_split), 3):\n","    print(example)"]},{"cell_type":"markdown","metadata":{"id":"gEgOXqAAlg7I"},"source":["## Vocabulario (a partir del train split)"]},{"cell_type":"markdown","metadata":{"id":"zekFPQqWlnmY"},"source":["Ahora construiremos el vocabulario, para esto necesitamos un tokenizador, pero ``torchtext`` no tiene un tokenizador para español así que bajaremos uno de ``spacy``"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9476,"status":"ok","timestamp":1655420035530,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"B_M21_JWlkkW","outputId":"9955458d-12b7-45cd-8640-1d17da777138","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting es_core_news_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2 MB)\n","\u001b[K     |████████████████████████████████| 16.2 MB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.64.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.9.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.21.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.7)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n","Building wheels for collected packages: es-core-news-sm\n","  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-py3-none-any.whl size=16172933 sha256=8d555ff5f5b468b29a3daaaa36a39332aacf1288bed1d528a1d8a52e67282be5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-paglmlul/wheels/21/8d/a9/6c1a2809c55dd22cd9644ae503a52ba6206b04aa57ba83a3d8\n","Successfully built es-core-news-sm\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('es_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/es_core_news_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/es\n","You can now load the model via spacy.load('es')\n"]}],"source":["!python -m spacy download es"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5344,"status":"ok","timestamp":1655420081280,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"_xgDAsk4lpiv","outputId":"0d1d9f0c-ce3f-4776-8e36-da7c96f89f40","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["8000lines [00:02, 3552.38lines/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Tamanno del vocabulario: 9393\n","Algunas palabras del vocabulario: ['respetuoso', 'comenzar', 'pasado', 'útil', 'campesinas']\n","\n","Cantidad de labels: 54\n","Algunos labels: ['Paz / Convivencia pacífica', 'Libertad de culto', 'Bien Común / Comunidad']\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Ahora si construiremos el vocabulario y la lista de labels\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","tokenizer = get_tokenizer(\"spacy\", \"es\")\n","vocab = build_vocab_from_iterator(tokenizer(text[1]) for text in train_split)\n","labels = list({doc[0] for doc in train_split})\n","label_map = {label: index for index, label in enumerate(labels)}\n","\n","print(\"\\nTamanno del vocabulario:\", len(vocab))\n","print(\"Algunas palabras del vocabulario:\", sample(vocab.itos, 5))\n","print(\"\\nCantidad de labels:\", len(labels))\n","print(\"Algunos labels:\", sample(labels, 3))"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1655420092796,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"aFWm6ulxlt4w","outputId":"40f5d7fd-9e65-4bad-d27a-6a15d7f40664","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["{'Amistad cívica': 49,\n"," 'Autonomía / Libertad': 8,\n"," 'Bien Común / Comunidad': 42,\n"," 'Ciudadanía': 12,\n"," 'Democracia': 33,\n"," 'Democracia participativa': 45,\n"," 'Derechos humanos': 24,\n"," 'Desarrollo': 36,\n"," 'Desarrollo integral': 3,\n"," 'Desarrollo sustentable': 4,\n"," 'Descentralización': 41,\n"," 'Dignidad': 39,\n"," 'Diversidad': 43,\n"," 'Emprendimiento libre': 37,\n"," 'Equidad': 20,\n"," 'Equidad de género': 48,\n"," 'Estado de Derecho': 50,\n"," 'Estado garante': 52,\n"," 'Estado laico': 7,\n"," 'Familia': 26,\n"," 'Familia basada en matrimonio heterosexual': 0,\n"," 'Identidad cultural': 19,\n"," 'Igualdad': 28,\n"," 'Inclasificable/No corresponde': 31,\n"," 'Inclusión': 44,\n"," 'Innovación / Creatividad': 16,\n"," 'Integración': 22,\n"," 'Justicia': 2,\n"," 'Justicia social': 18,\n"," 'Libertad': 47,\n"," 'Libertad de conciencia': 17,\n"," 'Libertad de culto': 9,\n"," 'Libertad de expresión': 15,\n"," 'Multiculturalidad': 11,\n"," 'Otro': 32,\n"," 'Participación': 27,\n"," 'Patriotismo': 25,\n"," 'Paz / Convivencia pacífica': 23,\n"," 'Pluralismo': 38,\n"," 'Plurinacionalismo': 13,\n"," 'Probidad': 21,\n"," 'Propiedad Privada': 51,\n"," 'República': 1,\n"," 'Respeto': 29,\n"," 'Respeto / Conservación de la naturaleza o medio ambiente': 35,\n"," 'Responsabilidad': 34,\n"," 'Seguridad': 5,\n"," 'Seguridad Social': 40,\n"," 'Soberanía': 10,\n"," 'Solidaridad': 53,\n"," 'Subsidiaridad': 14,\n"," 'Tolerancia': 46,\n"," 'Transparencia y publicidad': 6,\n"," 'Unidad': 30}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["label_map"]},{"cell_type":"markdown","metadata":{"id":"S5WUbpwDlvtX"},"source":["## Modelo con capa de Embedding"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1655420125122,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"SRGbqpOwlxi9","vscode":{"languageId":"python"}},"outputs":[],"source":["# Pum ahora hagamos la arquitectura\n","# simplecita, un capa de embedding, y luego una red feed forward de \n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Red neuronal con una sola capa escondida\n","class ArgumentClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_class, hidden_size, pad_idx):\n","        super().__init__()\n","\n","        # capa de embedding\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, pad_idx)\n","        # self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, mode=\"mean\")\n","\n","        # capas de la MLP\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        # self.fc1 = nn.Linear(embed_dim, hidden_size)\n","        # self.fc2 = nn.Linear(hidden_size, num_class)\n","\n","    def forward(self, batch):\n","        # La representacion de un documento sera el promedio de los\n","        # embeddings de sus palabras.\n","        # (B, N, 1) -> (B, N, E)\n","        h = self.embedding(batch)\n","        # (B, N, E) -> (B, E)\n","        h = h.mean(dim=1)\n","        # h = self.embedding(batch)\n","        \n","        # computar las capas de la red MLP\n","        h = self.fc(h)\n","        # h = F.relu(self.fc1(h))\n","        # h = self.fc2(h)\n","        \n","        return h\n","        # return torch.softmax(h, -1)"]},{"cell_type":"markdown","metadata":{"id":"pVq1K4tGl1cH"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"PybMd2z_l5BI"},"source":["Primero, necesitamos definir una función que convierta un conjunto de items de nuestro dataset en un batch,recordando que los tensores en pytorch tienen que ser homogeneos. Esta función recibe una lista de muestras del dataset y debe retornar tensores que agrupan estas muestras. \n","\n","Por ejemplo, si cada ejemplo de nuestro dataset contiene 2 elementos y nuestro tamanno de batch es de 16, entonces esta función debe retorna una tupla de 2 tensores, cada uno de dimension 16 x ... "]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1655420147036,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"L28eCml2l3DF","vscode":{"languageId":"python"}},"outputs":[],"source":["from itertools import zip_longest\n","\n","# creamos lista de tensores\n","train_dataset, validation_dataset = [\n","    [\n","        (\n","            label_map[item[0]],\n","            torch.tensor([vocab[token] for token in tokenizer(item[1])]),\n","        ) for item in split\n","    ] for split in [train_split, validation_split]\n","]"]},{"cell_type":"markdown","metadata":{"id":"BhMt7CZAkukz"},"source":["¿Pero que estamos haciendo en la lista de comprehesion anterior?... Bueno, basicamente estamos entregando los vectores de una forma legible por el computador, de tal forma que el modelo entienda en el entrenamiento una forma numerica de las palabras."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1655420164181,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"od2Xy8FzkTIH","outputId":"2e500e03-3396-462c-aa0f-4186ad576066","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["(2, tensor([ 117,    7,  275,   24,  252,   43,  717,    3,   45,    3,  571,    3,\n","          38,  445,    3,   24,   43,    9,    5, 1356,    4]))\n","(8, tensor([  52,    2, 1224,   20,   39,  452,  104]))\n"]}],"source":["# Lo que ve el comput\n","for data in sample(train_dataset, 2):\n","  print(data)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1655420169150,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"wKZhS0VIkuIn","outputId":"6c0c6eeb-574e-4bf4-cb0e-a6f4bf1a29e1","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["label: Autonomía / Libertad\n","text: libertad de gobernar por sus propias leyes \n"]}],"source":["# Lo que vería un humano\n","for key in label_map:\n","  if label_map[key] == data[0]:\n","    print(f\"label: {key}\")\n","\n","human_text = ''\n","for i in data[1]:\n","  human_text += vocab.itos[i] + ' '\n","print(f\"text: {human_text}\")"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1655420181351,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"sHT0-U4vNP2U","vscode":{"languageId":"python"}},"outputs":[],"source":["def generate_batch(batch):\n","    return (\n","        # En este caso como los labels son números, \n","        # el tensor es de una sola dimension de tamanno batch_size\n","        torch.tensor([item[0] for item in batch]),\n","\n","        # En este caso se retorna un tensor de 2 dimensiones, batch_size x N,\n","        # donde N es mayor largo de los ejemplo en el batch. Aca se realiza\n","        # padding de los ejemplos mas cortos.\n","        torch.tensor(\n","            list(\n","                zip(\n","                    *zip_longest(\n","                        *[item[1] for item in batch], fillvalue=vocab[\"<pad>\"]\n","                    )\n","                )\n","            )\n","        ),\n","    )"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1655420184825,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"tHOKyrL7l7t5","vscode":{"languageId":"python"}},"outputs":[],"source":["# Ahora creamos funciones para entrenar y validar el modelo\n","from torch.utils.data import DataLoader\n","\n","\n","def train_func(train_dataset):\n","\n","    # Entranamos el modelo\n","    train_loss = 0\n","    train_acc = 0\n","    data = DataLoader(\n","        train_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        collate_fn=generate_batch,\n","    )\n","    for i, (cls, text) in enumerate(data):\n","        optimizer.zero_grad()\n","        cls, text = cls.to(device), text.to(device)\n","        output = model(text)\n","        \n","        loss = criterion(output, cls)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        \n","        train_acc += (output.argmax(1) == cls).sum().item()\n","\n","    # Ajustar el learning rate\n","    # scheduler.step()\n","\n","    return train_loss / len(train_dataset), train_acc / len(train_dataset)\n","\n","\n","def test(test_dataset):\n","    test_loss = 0\n","    acc = 0\n","    data = DataLoader(\n","        test_dataset, batch_size=BATCH_SIZE, collate_fn=generate_batch\n","    )\n","    for cls, text in data:\n","        cls, text = cls.to(device), text.to(device)\n","        with torch.no_grad():\n","            output = model(text)\n","            loss = criterion(output, cls)\n","            test_loss += loss.item()\n","            acc += (output.argmax(1) == cls).sum().item()\n","\n","    return test_loss / len(test_dataset), acc / len(test_dataset)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11073,"status":"ok","timestamp":1655420198879,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"UkUm9pQal8zo","outputId":"ee22a62f-5f17-4a9d-853f-f1820f6df7bb","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1  | time in 0 minutes, 1 seconds\n","\tLoss: 0.1968(train)\t|\tAcc: 21.2%(train)\n","\tLoss: 0.1832(valid)\t|\tAcc: 27.1%(valid)\n","Epoch: 2  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1679(train)\t|\tAcc: 33.2%(train)\n","\tLoss: 0.1674(valid)\t|\tAcc: 32.4%(valid)\n","Epoch: 3  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1507(train)\t|\tAcc: 40.4%(train)\n","\tLoss: 0.1575(valid)\t|\tAcc: 37.5%(valid)\n","Epoch: 4  | time in 0 minutes, 1 seconds\n","\tLoss: 0.1384(train)\t|\tAcc: 45.2%(train)\n","\tLoss: 0.1497(valid)\t|\tAcc: 40.4%(valid)\n","Epoch: 5  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1289(train)\t|\tAcc: 48.8%(train)\n","\tLoss: 0.1443(valid)\t|\tAcc: 42.2%(valid)\n","Epoch: 6  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1208(train)\t|\tAcc: 50.9%(train)\n","\tLoss: 0.1406(valid)\t|\tAcc: 44.2%(valid)\n","Epoch: 7  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1142(train)\t|\tAcc: 53.7%(train)\n","\tLoss: 0.1376(valid)\t|\tAcc: 45.4%(valid)\n","Epoch: 8  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1084(train)\t|\tAcc: 56.2%(train)\n","\tLoss: 0.1349(valid)\t|\tAcc: 46.5%(valid)\n","Epoch: 9  | time in 0 minutes, 0 seconds\n","\tLoss: 0.1033(train)\t|\tAcc: 57.6%(train)\n","\tLoss: 0.1345(valid)\t|\tAcc: 46.9%(valid)\n","Epoch: 10  | time in 0 minutes, 0 seconds\n","\tLoss: 0.0989(train)\t|\tAcc: 59.2%(train)\n","\tLoss: 0.1320(valid)\t|\tAcc: 47.8%(valid)\n"]}],"source":["# Ahora por fin tenemos todo lo necesario para entrenar el modelo.\n","import time\n","\n","N_EPOCHS = 10\n","LEARN_RATE = 2.0\n","STEP_SIZE = 1\n","BATCH_SIZE = 16\n","EMBED_DIM = 100\n","HIDDEN_SIZE = 1024\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = ArgumentClassifier(\n","    vocab_size=len(vocab),\n","    embed_dim=EMBED_DIM,\n","    num_class=len(labels),\n","    hidden_size=HIDDEN_SIZE,\n","    pad_idx=vocab[\"<pad>\"],\n",").to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARN_RATE)\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, STEP_SIZE)\n","\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    train_loss, train_acc = train_func(train_dataset)\n","    valid_loss, valid_acc = test(validation_dataset)\n","\n","    secs = int(time.time() - start_time)\n","    mins = secs // 60\n","    secs = secs % 60\n","\n","    print(\n","        f\"Epoch: {epoch + 1}\", f\" | time in {mins} minutes, {secs} seconds\",\n","    )\n","    print(\n","        f\"\\tLoss: {train_loss:.4f}(train)\\t|\"\n","        f\"\\tAcc: {train_acc * 100:.1f}%(train)\"\n","    )\n","    print(\n","        f\"\\tLoss: {valid_loss:.4f}(valid)\\t|\"\n","        f\"\\tAcc: {valid_acc * 100:.1f}%(valid)\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"d2DyCzBUbfwk"},"source":["# Parte 3: Pero en la tarea nos piden hacer una red con CNN... como se hacen?"]},{"cell_type":"markdown","metadata":{"id":"5HylpfYQcADP"},"source":["Para este caso vamos a trabajar con un dataset de noticias, el cual es fácilmente descargable con la librería y da muchos mejores resultados (ya que los anteriores estaban ahí nomas)."]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6870,"status":"ok","timestamp":1655420230388,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"mZgbo70IcGrq","outputId":"a0ab8c3c-ca29-4309-8f82-493cd249b4d2","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["train.csv: 29.5MB [00:01, 23.0MB/s]\n","test.csv: 1.86MB [00:00, 56.4MB/s]                  \n","120000lines [00:03, 32851.52lines/s]\n"]}],"source":["# por si las moscas importamos todo denuevo (para los que recién se unen a la sintonia)\n","# https://pytorch.org/text/stable/datasets.html#ag-news\n","import os\n","import torch\n","from random import choice\n","from torchtext.datasets import AG_NEWS\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","os.makedirs(\"data\", exist_ok=True)\n","train_dataset, test_dataset = AG_NEWS(root=\"data\", split=('train', 'test'))\n","train_list = list(train_dataset)\n","test_list = list(test_dataset)\n","\n","# Informacion relevante del dataset\n","tokenizer = get_tokenizer(\"basic_english\")\n","vocab = build_vocab_from_iterator(tokenizer(x[1]) for x in train_list)\n","num_classes = 4"]},{"cell_type":"markdown","metadata":{"id":"bTNLFNbTc5rx"},"source":["Luego, creamos una red no tan profunda pero bien competente para nuestra tarea:"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":247,"status":"ok","timestamp":1655420261561,"user":{"displayName":"JOSE LUIS ANTONIO CADIZ","userId":"01931834456197558553"},"user_tz":240},"id":"HOwf8CZZctxG","vscode":{"languageId":"python"}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from itertools import zip_longest\n","\n","class CNNClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=32, num_classes=10, \n","                 cnn_pool_channels=24, cnn_kernel_size=3):\n","      super().__init__()\n","      \n","\n","      # capa de embedding\n","      self.embedding = nn.Embedding(vocab_size, embed_dim)\n","\n","      # capa de convolución\n","      self.conv = nn.Conv1d(\n","          in_channels=1,\n","          out_channels=cnn_pool_channels,\n","          kernel_size=cnn_kernel_size * embed_dim,\n","          stride=embed_dim,\n","      )\n","\n","      fc_in_size = cnn_pool_channels\n","\n","      # capa lineal\n","      self.fc = nn.Linear(fc_in_size, num_classes)\n","\n","      self.init_weights()\n","\n","    def init_weights(self):\n","      initrange = 0.5\n","      self.embedding.weight.data.uniform_(-initrange, initrange)\n","      self.fc.weight.data.uniform_(-initrange, initrange)\n","      self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","      # preparamos el input de la capa de embeddings a partir de text y offsets\n","      # (N x longest_text)\n","      text = torch.tensor(\n","          list(\n","              zip(\n","                  *zip_longest(\n","                      *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]), \n","                      fillvalue=vocab[\"<pad>\"]\n","                  )\n","              )\n","          )\n","      ).to(text.device)\n","\n","      # (N x longest_text x embed_dim)\n","      h = self.embedding(text)\n","\n","      # (N x pool_channels)\n","      h = h.view(h.size(0), 1, -1)\n","      h = torch.relu(self.conv(h))\n","      h = h.mean(dim=2)\n","\n","      # (N x num_classes)\n","      return self.fc(h)"]},{"cell_type":"markdown","metadata":{"id":"pLOXQIhec4PY"},"source":["Finalmente, generamos la función para cargar por batch y luego entrenamos directamente."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSx0x-kocxMA","outputId":"a31fe233-4230-46e5-a139-3cf2b5d43e1c","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","Epoch: 001\t Phase: train Iter: 7500/7500\t iter-Acc: 93.750%\t iter-Loss: 0.142\n"," train\tAvg. Acc: 61.205%\t Avg. Loss: 0.057\n","Epoch: 001\t Phase: test Iter: 095/095\t iter-Acc: 83.750%\t iter-Loss: 0.425\n"," test\tAvg. Acc: 79.039%\t Avg. Loss: 0.007\n","Epoch: 002\t Phase: train Iter: 7500/7500\t iter-Acc: 93.750%\t iter-Loss: 0.097\n"," train\tAvg. Acc: 84.952%\t Avg. Loss: 0.027\n","Epoch: 002\t Phase: test Iter: 095/095\t iter-Acc: 86.250%\t iter-Loss: 0.307\n"," test\tAvg. Acc: 84.895%\t Avg. Loss: 0.006\n","Epoch: 003\t Phase: train Iter: 5730/7500\t iter-Acc: 93.750%\t iter-Loss: 0.280"]}],"source":["import sys\n","from torch.optim import SGD, lr_scheduler\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","def generate_batch(batch):\n","  label = torch.tensor([entry[0]-1 for entry in batch])\n","  texts = [tokenizer(entry[1]) for entry in batch]\n","  offsets = [0] + [len(text) for text in texts]\n","  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","  big_text = torch.cat([torch.tensor([vocab.stoi[t] for t in text]) for text in texts])\n","  return big_text, offsets, label\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 50\n","TEST_BATCH_SIZE = BATCH_SIZE * 5\n","LR = 1e-1\n","\n","model = CNNClassifier(len(vocab), num_classes=num_classes).to(device)\n","optimizer = SGD(model.parameters(), lr=LR)\n","criterion = nn.CrossEntropyLoss().to(device)\n","scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n","\n","split_size = {'train': len(train_list), 'test': len(test_list)}\n","\n","# train_dataset, test_dataset = AG_NEWS(root=\"data\")\n","for epoch in range(1, NUM_EPOCHS):\n","  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n","  test_loader = DataLoader(test_list, batch_size=TEST_BATCH_SIZE, collate_fn=generate_batch)\n","  loaders = {'train': train_loader, 'test': test_loader}\n","  for phase in ['train', 'test']:\n","    if phase == 'train':\n","      model.train()\n","    else:\n","      model.eval()\n","\n","    total_acc, total_loss = 0, 0\n","    for i, (texts, offsets, cls) in enumerate(loaders[phase]):\n","      texts = texts.to(device)\n","      offsets = offsets.to(device)\n","      cls = cls.to(device)\n","\n","      optimizer.zero_grad()\n","      with torch.set_grad_enabled(phase == 'train'):\n","        output = model(texts, offsets)\n","        loss = criterion(output, cls)\n","        total_loss += loss.item()\n","        if phase == 'train':\n","          loss.backward()\n","          optimizer.step()\n","      \n","      acc = (output.argmax(1) == cls).sum().item()\n","      total_acc += acc\n","\n","      sys.stdout.write('\\rEpoch: {0:03d}\\t Phase: {1} Iter: {2:03d}/{3:03d}\\t iter-Acc: {4:.3f}%\\t iter-Loss: {5:.3f}'.format(epoch, phase, i+1, len(loaders[phase]), acc/len(offsets)*100, loss.item()))\n","\n","    if phase == 'train':\n","      scheduler.step()\n","    print('\\n {0}\\tAvg. Acc: {1:.3f}%\\t Avg. Loss: {2:.3f}'.format(phase, total_acc/split_size[phase]*100, total_loss/split_size[phase]))"]},{"cell_type":"markdown","metadata":{"id":"2NuHEAZsdL1u"},"source":["Como podemos ver, con esta segunda perspectiva tenemos un clasificador mas competente en relación con el anterior. La idea es que tengan diferente perspectivas en la construcción."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Auxiliar_Pytorch.ipynb","provenance":[{"file_id":"1zTKFL13jWCiGP2YZGWaFVGi4LSRwPEXc","timestamp":1655419617808}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
